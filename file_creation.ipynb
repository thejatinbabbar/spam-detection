{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "file_creation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1lz7pu6SyatMEowXFjdONVz9Qf3xZnchY",
      "authorship_tag": "ABX9TyM4w5na7bVrxJjbf9TM1R4R"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTJPz8dOIFHE",
        "outputId": "8d4fd98c-f7b8-41fd-c5b3-f6ff83f33bfa"
      },
      "source": [
        "%%writefile /content/drive/MyDrive/data_mining/notebooks/feature_selection.py\n",
        "# importing modules\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "def import_files(data_path):\n",
        "    \"\"\"\n",
        "    Import the files and join the features with the labels to obtain a single dataframe\n",
        "    \"\"\"\n",
        "    users = os.path.join(data_path, 'users')\n",
        "    users_features = os.path.join(data_path, 'users_features')\n",
        "\n",
        "    coded_ids = pd.read_csv(os.path.join(users,'coded_ids.csv')).set_index('coded_id')\n",
        "    coded_ids_labels_train = pd.read_csv(os.path.join(users,'coded_ids_labels_train.csv')).set_index('coded_id')\n",
        "    coded_ids = coded_ids.join(coded_ids_labels_train)\n",
        "    coded_ids.reset_index(inplace=True)\n",
        "    coded_ids.set_index('user_id', inplace=True)\n",
        "\n",
        "    features = pd.read_csv(os.path.join(users_features, 'features.csv')).set_index('user_id')\n",
        "    # features_names = pd.read_csv(os.path.join(users_features, 'features_names.txt'), header=None)\n",
        "\n",
        "    data = features.join(coded_ids)\n",
        "    data.reset_index(inplace=True, drop=True)\n",
        "    data.set_index('coded_id', inplace=True)\n",
        "    data.sort_index(inplace=True)\n",
        "\n",
        "    return data\n",
        "\n",
        "def get_clean_data(data_path):\n",
        "    \"\"\"\n",
        "    Clean the dataset by:\n",
        "\n",
        "    1. encode categorical variable\n",
        "    2. remove unnecessary features\n",
        "    3. fill null values\n",
        "    4. convert datetime to timestamp\n",
        "    \"\"\"\n",
        "    data = import_files(data_path)\n",
        "\n",
        "    encoder = LabelEncoder()\n",
        "    data['lang'] = encoder.fit_transform(data['lang'])\n",
        "    data['time_zone'] = encoder.fit_transform(data['time_zone'].astype(str))\n",
        "    data['date_newest_tweet'] = pd.to_datetime(data['date_newest_tweet']).astype('int64') // 10 ** 9\n",
        "    data['date_oldest_tweet'] = pd.to_datetime(data['date_oldest_tweet']).astype('int64') // 10 ** 9\n",
        "    data['utc_offset'] = data['utc_offset'].fillna(0)\n",
        "\n",
        "    cols_to_remove = ['avg_intertweet_times',\n",
        "                      'max_intertweet_times',\n",
        "                      'min_intertweet_times',\n",
        "                      'std_intertweet_times',\n",
        "                      'followers_count_minus_2002',\n",
        "                      'friends_count_minus_2002',\n",
        "                      'spam_in_screen_name']\n",
        "    data.drop(cols_to_remove, axis=1, inplace=True)\n",
        "\n",
        "    return data\n",
        "\n",
        "def get_feature_groups(data):\n",
        "    \"\"\"\n",
        "    Create different feature groups based on the correlation score with the target variable\n",
        "\n",
        "    1. all columns\n",
        "    2. columns with correlation score > 0.2\n",
        "    3. columns with correlation score > 0.3\n",
        "    4. top 30 columns with chi square score\n",
        "    5. top 50 columns with chi square score\n",
        "    6. top 80 columns with chi square score\n",
        "    \"\"\"\n",
        "    groups = []\n",
        "    groups.append(data.columns)\n",
        "    groups.append(data.corr()[data.corr().label.abs() > 0.2].label.index.values)\n",
        "    groups.append(data.corr()[data.corr().label.abs() > 0.3].label.index.values)\n",
        "    \n",
        "    scaler = MinMaxScaler()\n",
        "    data_new = scaler.fit_transform(data[data.label.notnull()].drop('label', axis=1))\n",
        "    selector = SelectKBest(chi2, k=30)\n",
        "    selector.fit(data_new, data[data.label.notnull()]['label'])\n",
        "    indices =[i for i, x in enumerate(selector.get_support()) if x]\n",
        "    group = [data.columns[i] for i in indices]\n",
        "    group.append('label')\n",
        "    groups.append(group)\n",
        "\n",
        "    selector = SelectKBest(chi2, k=50)\n",
        "    selector.fit(data_new, data[data.label.notnull()]['label'])\n",
        "    indices =[i for i, x in enumerate(selector.get_support()) if x]\n",
        "    group = [data.columns[i] for i in indices]\n",
        "    group.append('label')\n",
        "    groups.append(group)\n",
        "\n",
        "    selector = SelectKBest(chi2, k=80)\n",
        "    selector.fit(data_new, data[data.label.notnull()]['label'])\n",
        "    indices =[i for i, x in enumerate(selector.get_support()) if x]\n",
        "    group = [data.columns[i] for i in indices]\n",
        "    group.append('label')\n",
        "    groups.append(group)\n",
        "\n",
        "    return groups\n",
        "\n",
        "def get_train_and_test_set(data_path):\n",
        "    \"\"\"\n",
        "    Split the dataset into train set and test set for each feature group\n",
        "    \"\"\"\n",
        "    data = get_clean_data(data_path)\n",
        "    groups = get_feature_groups(data)\n",
        "\n",
        "    train_set = []\n",
        "    test_set = []\n",
        "    for columns in groups:\n",
        "\n",
        "        train = data[columns][data.label.notnull()].copy()\n",
        "        test = data[columns][data.label.isnull()].copy()\n",
        "        train_set.append(train)\n",
        "        test_set.append(test)\n",
        "\n",
        "    return train_set, test_set"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/data_mining/notebooks/feature_selection.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kU1RDq8LEyq",
        "outputId": "aa61920f-fc1d-45ca-938d-73a9bdb53ae3"
      },
      "source": [
        "%%writefile /content/drive/MyDrive/data_mining/notebooks/models_with_crossval.py\n",
        "# importing modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import set_config\n",
        "from feature_selection import get_train_and_test_set\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
        "\n",
        "set_config(print_changed_only=True)\n",
        "\n",
        "def get_crossval_scores(data_path):\n",
        "    \"\"\"\n",
        "    Perform cross validation on the dataset and fit on different models\n",
        "    \"\"\"\n",
        "\n",
        "    models = [KNeighborsClassifier(n_neighbors=5),\n",
        "              DecisionTreeClassifier(),\n",
        "              RandomForestClassifier(),\n",
        "              RandomForestClassifier(n_estimators=200),\n",
        "              GradientBoostingClassifier(),\n",
        "              GradientBoostingClassifier(n_estimators=200)]\n",
        "    train_set, _ = get_train_and_test_set(data_path)\n",
        "\n",
        "    scores = {}\n",
        "    for model in models:\n",
        "        scores[model] = {}\n",
        "\n",
        "    print('Cross Validation Score')\n",
        "\n",
        "    for model in models:\n",
        "        print(model)\n",
        "        for i, train in enumerate(train_set, 1):\n",
        "            X, y = train.drop('label', axis=1), train['label']\n",
        "            cv = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
        "            score = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
        "            scores[model][f'group {i}'] = score\n",
        "            print('---- feature group', i, ':', score, 'Mean:', np.mean(score))\n",
        "        print()\n",
        "\n",
        "    return scores"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/data_mining/notebooks/models_with_crossval.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRx1wx3J23Rv",
        "outputId": "11f37b33-96e7-4643-e2d5-34f4f5f979d5"
      },
      "source": [
        "%%writefile /content/drive/MyDrive/data_mining/notebooks/make_predictions.py\n",
        "# importing modules\n",
        "import os\n",
        "import pandas as pd\n",
        "from feature_selection import get_train_and_test_set\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "def predict(data_path):\n",
        "    \"\"\"\n",
        "    Choose \n",
        "    1. the best model (Gradient Boosting Classfier) \n",
        "    2. the best feature group (feature group 6)\n",
        "    to fit the model and make predictions for test set\n",
        "    \"\"\"\n",
        "    print('Making predictions for test set ...')\n",
        "    test_file = os.path.join(data_path,'users','coded_ids_labels_test.csv')\n",
        "    test_df = pd.read_csv(test_file)\n",
        "\n",
        "    train_set, test_set = get_train_and_test_set(data_path)\n",
        "    train = train_set[5]\n",
        "    test = test_set[5]\n",
        "\n",
        "    model = GradientBoostingClassifier(n_estimators=200)\n",
        "\n",
        "    model.fit(train.drop('label',axis=1), train['label'])\n",
        "    preds = model.predict(test.drop('label', axis=1))\n",
        "    test_df['label'] = preds\n",
        "\n",
        "    print('Saving test file ...')\n",
        "    test_file = os.path.join(data_path,'users','coded_ids_labels_test_1.csv')\n",
        "    test_df.to_csv(test_file, index=False)\n",
        "\n",
        "    print('Done!')\n",
        "    return"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/data_mining/notebooks/make_predictions.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE6-f6nndKuz",
        "outputId": "4c1693b5-317e-4957-f963-16a9553c114d"
      },
      "source": [
        "%%writefile /content/drive/MyDrive/data_mining/notebooks/main.py\n",
        "# importing modules\n",
        "from models_with_crossval import get_crossval_scores\n",
        "from make_predictions import predict\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    data_path = '/content/drive/MyDrive/data_mining/Social_spammers_dataset'\n",
        "    scores = get_crossval_scores(data_path)\n",
        "    predict(data_path)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/data_mining/notebooks/main.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaDXHFysdKkX",
        "outputId": "e8e6b605-a618-4601-c571-d16cca3074bb"
      },
      "source": [
        "!python /content/drive/MyDrive/data_mining/notebooks/main.py"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross Validation Score\n",
            "KNeighborsClassifier()\n",
            "---- feature group 1 : [0.91860465 0.86046512 0.90116279 0.86627907 0.85465116] Mean: 0.8802325581395349\n",
            "---- feature group 2 : [0.91860465 0.86046512 0.90116279 0.86627907 0.85465116] Mean: 0.8802325581395349\n",
            "---- feature group 3 : [0.87790698 0.84302326 0.90116279 0.83139535 0.84883721] Mean: 0.8604651162790697\n",
            "---- feature group 4 : [0.8372093  0.81395349 0.83139535 0.86627907 0.84883721] Mean: 0.8395348837209301\n",
            "---- feature group 5 : [0.8255814  0.80813953 0.84302326 0.86627907 0.86046512] Mean: 0.8406976744186047\n",
            "---- feature group 6 : [0.90116279 0.87790698 0.87790698 0.86627907 0.84883721] Mean: 0.8744186046511627\n",
            "\n",
            "DecisionTreeClassifier()\n",
            "---- feature group 1 : [0.96511628 0.9244186  0.97093023 0.94767442 0.95930233] Mean: 0.9534883720930232\n",
            "---- feature group 2 : [0.96511628 0.93604651 0.97093023 0.97674419 0.94186047] Mean: 0.9581395348837208\n",
            "---- feature group 3 : [0.96511628 0.91860465 0.96511628 0.93604651 0.94767442] Mean: 0.9465116279069768\n",
            "---- feature group 4 : [0.95930233 0.94767442 0.97093023 0.93604651 0.9244186 ] Mean: 0.9476744186046512\n",
            "---- feature group 5 : [0.95348837 0.93023256 0.95930233 0.96511628 0.93604651] Mean: 0.9488372093023256\n",
            "---- feature group 6 : [0.95348837 0.93023256 0.97093023 0.98255814 0.95348837] Mean: 0.9581395348837211\n",
            "\n",
            "RandomForestClassifier()\n",
            "---- feature group 1 : [0.95348837 0.95348837 0.98255814 0.97674419 0.96511628] Mean: 0.9662790697674419\n",
            "---- feature group 2 : [0.97093023 0.93023256 0.98255814 0.95930233 0.95348837] Mean: 0.9593023255813954\n",
            "---- feature group 3 : [0.96511628 0.93023256 0.98255814 0.98837209 0.95930233] Mean: 0.9651162790697676\n",
            "---- feature group 4 : [0.96511628 0.93604651 0.98255814 0.98837209 0.95930233] Mean: 0.9662790697674419\n",
            "---- feature group 5 : [0.97674419 0.94767442 0.98837209 0.98255814 0.95930233] Mean: 0.9709302325581396\n",
            "---- feature group 6 : [0.95348837 0.95348837 0.98837209 0.97093023 0.96511628] Mean: 0.9662790697674419\n",
            "\n",
            "RandomForestClassifier(n_estimators=200)\n",
            "---- feature group 1 : [0.95348837 0.94767442 0.97674419 0.97093023 0.95348837] Mean: 0.9604651162790698\n",
            "---- feature group 2 : [0.97093023 0.93604651 0.98255814 0.97674419 0.95930233] Mean: 0.9651162790697674\n",
            "---- feature group 3 : [0.97093023 0.91860465 0.98255814 0.97674419 0.96511628] Mean: 0.9627906976744185\n",
            "---- feature group 4 : [0.97093023 0.94186047 0.98255814 0.97674419 0.95930233] Mean: 0.9662790697674419\n",
            "---- feature group 5 : [0.97674419 0.94767442 0.97674419 0.99418605 0.96511628] Mean: 0.9720930232558139\n",
            "---- feature group 6 : [0.96511628 0.94186047 0.98255814 0.97093023 0.96511628] Mean: 0.9651162790697676\n",
            "\n",
            "GradientBoostingClassifier()\n",
            "---- feature group 1 : [0.97093023 0.96511628 0.98255814 0.98255814 0.95348837] Mean: 0.9709302325581396\n",
            "---- feature group 2 : [0.97093023 0.94767442 0.97093023 0.98837209 0.96511628] Mean: 0.9686046511627907\n",
            "---- feature group 3 : [0.97093023 0.93604651 0.97093023 0.98837209 0.97093023] Mean: 0.9674418604651163\n",
            "---- feature group 4 : [0.97674419 0.94767442 0.98255814 0.97093023 0.95348837] Mean: 0.9662790697674419\n",
            "---- feature group 5 : [0.96511628 0.94186047 0.97093023 0.98837209 0.97093023] Mean: 0.9674418604651163\n",
            "---- feature group 6 : [0.97093023 0.95930233 0.98837209 0.99418605 0.95930233] Mean: 0.9744186046511627\n",
            "\n",
            "GradientBoostingClassifier(n_estimators=200)\n",
            "---- feature group 1 : [0.97093023 0.95348837 0.97674419 0.99418605 0.95930233] Mean: 0.9709302325581396\n",
            "---- feature group 2 : [0.97093023 0.95348837 0.97093023 0.98837209 0.96511628] Mean: 0.969767441860465\n",
            "---- feature group 3 : [0.97093023 0.93604651 0.98837209 0.97674419 0.95930233] Mean: 0.9662790697674419\n",
            "---- feature group 4 : [0.97674419 0.94186047 0.98837209 0.97674419 0.94186047] Mean: 0.9651162790697674\n",
            "---- feature group 5 : [0.96511628 0.94186047 0.97674419 0.98837209 0.97093023] Mean: 0.9686046511627907\n",
            "---- feature group 6 : [0.97093023 0.95930233 0.97674419 1.         0.96511628] Mean: 0.9744186046511627\n",
            "\n",
            "Making predictions for test set ...\n",
            "Saving test file ...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5xLFIqIIaN4",
        "outputId": "88f58c0d-fa15-4ca6-a159-83afdd2cba99"
      },
      "source": [
        "%%writefile /content/drive/MyDrive/data_mining/notebooks/ml_models.py\n",
        "# importing modules\n",
        "from feature_selection import get_train_and_val_set\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "def train(model, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Fit the model and return the train score\n",
        "    \"\"\"\n",
        "    model.fit(X_train, y_train)\n",
        "    score = model.score(X_train, y_train)\n",
        "\n",
        "    return score\n",
        "\n",
        "def evaluate(model, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the validation set and return the val score\n",
        "    \"\"\"\n",
        "    score = model.score(X_val, y_val)\n",
        "\n",
        "    return score\n",
        "\n",
        "def predict(model, X_test):\n",
        "    \"\"\"\n",
        "    Predict the labels for the test set\n",
        "    \"\"\"\n",
        "    preds = model.predict(X_test)\n",
        "    \n",
        "    return preds\n",
        "\n",
        "data_path = '/content/drive/MyDrive/data_mining/Social_spammers_dataset'\n",
        "models = [DecisionTreeClassifier(),\n",
        "          RandomForestClassifier(),\n",
        "          GradientBoostingClassifier()]\n",
        "train_val_set = get_train_and_val_set(data_path)\n",
        "\n",
        "scores = {}\n",
        "for model in models:\n",
        "    scores[type(model).__name__] = {'train_scores': [], 'val_scores': []}\n",
        "\n",
        "for model in models:\n",
        "    print(type(model).__name__)\n",
        "    for i, (X_train, y_train, X_val, y_val) in enumerate(train_val_set, 1):\n",
        "        score = train(model, X_train, y_train)\n",
        "        scores[type(model).__name__]['train_scores'].append(score)\n",
        "        print('---- train score', i, ':', score)\n",
        "\n",
        "        score = evaluate(model, X_val, y_val)\n",
        "        scores[type(model).__name__]['val_scores'].append(score)\n",
        "        print('---- val score', i, ':', score)\n",
        "        print()\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/data_mining/notebooks/ml_models.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UE0nC7aMgBr",
        "outputId": "73822000-cf76-4a1a-df25-a4e37831ba6c"
      },
      "source": [
        "!python /content/drive/MyDrive/data_mining/notebooks/ml_models.py"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier\n",
            "---- train score 1 : 1.0\n",
            "---- val score 1 : 0.9302325581395349\n",
            "\n",
            "---- train score 2 : 1.0\n",
            "---- val score 2 : 0.9534883720930233\n",
            "\n",
            "---- train score 3 : 1.0\n",
            "---- val score 3 : 0.9534883720930233\n",
            "\n",
            "---- train score 4 : 1.0\n",
            "---- val score 4 : 0.9651162790697675\n",
            "\n",
            "RandomForestClassifier\n",
            "---- train score 1 : 1.0\n",
            "---- val score 1 : 0.9767441860465116\n",
            "\n",
            "---- train score 2 : 1.0\n",
            "---- val score 2 : 0.9767441860465116\n",
            "\n",
            "---- train score 3 : 1.0\n",
            "---- val score 3 : 0.9767441860465116\n",
            "\n",
            "---- train score 4 : 1.0\n",
            "---- val score 4 : 0.9651162790697675\n",
            "\n",
            "GradientBoostingClassifier\n",
            "---- train score 1 : 1.0\n",
            "---- val score 1 : 0.9883720930232558\n",
            "\n",
            "---- train score 2 : 1.0\n",
            "---- val score 2 : 0.9767441860465116\n",
            "\n",
            "---- train score 3 : 1.0\n",
            "---- val score 3 : 0.9767441860465116\n",
            "\n",
            "---- train score 4 : 1.0\n",
            "---- val score 4 : 0.9651162790697675\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}